\documentclass[a4paper]{article}
\usepackage[margin=1in]{geometry}
\begin{document}
% ---- Beginn Analysis -----
\begin{center}
\section*{Analysis of Mean Stain Levels}
\end{center}
The aim of this analysis is to see if there are significant differences between platinum responders and non-responders in the protein levels measured by fluidigm. This will give us information about which processes might be important in determining good response to platinum, and as such might allow us to reduce the dimensionality of our data and better target our deep learning approaches. In addition, the results might be interesting by themselves.
\\
\\
In doing this analysis the following resources have been very helpful:
\begin{itemize}
\item My MT5753 Notes
\item https://www.r-bloggers.com/how-to-perform-a-logistic-regression-in-r/ for a short and good intro to logistic regression
\end{itemize}


% =======================================================
% ---- Naive Logistic Model -----
\section{A Simple Logistic Regression Model}
The aim is to find a relationship between the mean levels of the different stains for a patient and the patients response to platinum treatment. The response is binary (1=Response,0=Non-Response), whereas the stain levels are continous variables. A good way of modelling such a binary relationship is using a logistic model. A logistic model models the log odds of responding to platinum vs not-responding as a linear function of the mean stain levels. For a good introduction, this webpage was very helpful:\\
https://www.r-bloggers.com/how-to-perform-a-logistic-regression-in-r/
\\
I will follow the steps from this webpage to build a first model.
To begin with let us load the data.
<<tidy=F,results='markup'>>=
stainSummaryArr = read.csv("rawStainSummaries.csv",header=F)
names(stainSummaryArr) = c("StainId","MeanStain","TotStain","PtSnty","CoreId")
dim(stainSummaryArr)
@
As it stands the data is in the wrong format. We need it in long format. So, do this conversion:
<<tidy=F,results='markup'>>=
meanStain_Wide = data.frame()
for (coreId in unique(stainSummaryArr$CoreId)) {
  tmp_MeanStain = stainSummaryArr$MeanStain[stainSummaryArr$CoreId==coreId]
  tmp_PtSnty = unique(stainSummaryArr$PtSnty[stainSummaryArr$CoreId==coreId])
  meanStain_Wide = rbind(meanStain_Wide,c(coreId, tmp_PtSnty, tmp_MeanStain))
}
# Add the proper marker names
markerLabelsVec = c('SrBCK', 'RR101', 'RR102', 'AvantiLipid', 'XeBCK', 'CD196', 'CD19', 'Vimentin', 'CD163', 'CD20', 'CD16', 'CD25', 'p53', 'CD134', 'CD45', 'CD44s', 'CD14', 'FoxP3', 'CD4', 'E-cadherin', 'p21', 'CD152', 'CD8a', 'CD11b', 'Beta-catenin', 'B7-H4', 'Ki67', 'CollagenI', 'CD3', 'CD68', 'PD-L2', 'B7-H3', 'HLA-DR', 'pS6', 'HistoneH3', 'DNA191', 'DNA193')
names(meanStain_Wide) = c("CoreId","PtSnty",markerLabelsVec)
@

In this analysis we are interested to see if the expression for a particular marker differs between the responding and resistant groups. However, the markers are naturally expressed/present at different levels, so that the scale for some markers will be much larger than for others. This can bias the analysis towards more highly expressed markers and make it difficult to build robust models. A way around this issue is to standardise the data so that each marker has mean 0 and standard deviation 1.

Let's do this and also remove the 'coreId' column, as we don't need this in the analysis
<<tidy=F,results='markup'>>=
# Standardise the data, using the caret preproces function. Note: preProcess can also do a Box-Cox transform
require(caret)
meanStainWide_Tranformed = meanStain_Wide
preprocessParams = preProcess(meanStain_Wide[,3:dim(meanStain_Wide)[2]],
                              method=c("center", "scale"),verbose=T)
meanStainWide_Tranformed[,3:dim(meanStain_Wide)[2]] =
  predict(preprocessParams, meanStain_Wide[,3:dim(meanStain_Wide)[2]])

# Remove the coreId column so that it doesn't influence the analysis
meanStainWide_Tranformed = cbind(meanStainWide_Tranformed$PtSnty,
                                 meanStainWide_Tranformed[,3:ncol(meanStainWide_Tranformed)])
names(meanStainWide_Tranformed) = c("PtSnty",markerLabelsVec)
# summary(meanStainWide_Tranformed)
@

The data is now transformed and we're ready to fit a logistic model. R makes this easy with the 'glm()' function:
<<tidy=F,results='markup'>>=
# Fit a logistic model to the full set of covariates
meanStain_LogitModel = glm(PtSnty ~.,family=binomial(link='logit'),
                           data=meanStainWide_Tranformed)

# Analyse the results
summary(meanStain_LogitModel)
@

Interesting, so we have a couple of significant coefficients, which indicates that these stains are different between responders and non-responders. Let's plot these results:

<<Fig_fullLogCoeff,tidy=F,results='markup',fig.pos="t", fig.cap="Importance of the different stains according to the logistic model.">>=
confLevel = 0.95 # Statistical confidence indicated by error bars
logitMCoeffs = meanStain_LogitModel$coefficients
logitMStdErrs = summary(meanStain_LogitModel)$coefficients[,2]
# Normalise
normFact = sum(abs(logitMCoeffs))
logitMCoeffs = logitMCoeffs*100/normFact
logitMStdErrs = logitMStdErrs*100/normFact
confIntLogitCoeffs = data.frame(MarkerLabels=markerLabelsVec,MeanCoeff=as.numeric(logitMCoeffs[2:length(logitMCoeffs)]),SE=logitMStdErrs[2:length(logitMStdErrs)],CI=qt(confLevel/2+.5, nrow(meanStainWide_Tranformed))*logitMStdErrs[2:length(logitMStdErrs)])
# Plot
ggplot(confIntLogitCoeffs,aes(x=MarkerLabels,y=MeanCoeff,fill=MeanCoeff)) +
  geom_bar(position=position_dodge(0.9), stat="identity") +
  geom_errorbar(aes(ymin=MeanCoeff-CI, ymax=MeanCoeff+CI),
                width=.8,                    # Width of the error bars
                position=position_dodge(0.9)) +
  theme_bw() +
  ylab("Relative size of the coefficient (in %)") +
  xlab("") +
  scale_fill_gradient(low="red",high="green4") +
  ggtitle(paste("Coefficients of Logistic Model",sep="")) +
  coord_flip()
@

This looks very similar to the LDA results (Figure \ref{fig:Fig_fullLogCoeff}). However, the error bars give a lot of additional insights. For LDA we had DNA191 and DNA193 also being very important, which was odd. Here we can see that while the coefficients of DNA191 and DNA193 are big, the uncertainty about them is also big. So, that it's not actually clear that they are important.

One result that was clear from the PCA was that there is a lot of correlation between the different stains. This is something that will influence a linear model. If there's strong correlation the model will struggle to distinguish between the influence of the different covariates (they all do the same thing) and so it becomes quite instable (See also: https://onlinecourses.science.psu.edu/stat501/node/346). To check for co-linearity, my MT5753 notes suggest to use ``variance inflation factors'' (VIF). These basically describe how well one covariate can be represented as a linear combination of the others. A VIF of greater than 5-10 is considered ``bad''.

VIFs can be calculated in R using the \texttt{car} library. Let's do it:
<<results='markup'>>=
# Co-linearity analysis
library(car)
vifVec = vif(meanStain_LogitModel)
vifVec[order(vifVec,decreasing=T)]
@

It seems like DNA193 and DNA191 seem to be strongly colinear and so do RR102 and RR101. This is nice given they're often just noise in the images and they also don't appear in the marker excel sheet. Let's remove them one at a time and see what it does.
<<results='markup'>>=
# Remove DNA193
meanStainWide_Tranformed = meanStainWide_Tranformed[,names(meanStainWide_Tranformed)!="DNA193"]
# Rerun the model
meanStain_LogitModel = glm(PtSnty ~.,family=binomial(link='logit'),
                           data=meanStainWide_Tranformed)
# Check the VIFs
vifVec = vif(meanStain_LogitModel)
vifVec[order(vifVec,decreasing=T)]
@

That brought DNA191 down, next let's take RR102.
<<results='markup'>>=
# Remove RR102
meanStainWide_Tranformed = meanStainWide_Tranformed[,names(meanStainWide_Tranformed)!="RR102"]
# Rerun the model
meanStain_LogitModel = glm(PtSnty ~.,family=binomial(link='logit'),
                           data=meanStainWide_Tranformed)
# Check the VIFs
vifVec = vif(meanStain_LogitModel)
vifVec[order(vifVec,decreasing=T)]
@

Ok, now we're left with CD68. The linear discriminant analysis brought this up as an important contributer. However, it seems to be quite strongly co-linear with other markers. Perhaps this is because CD68 is a generic Monocyte/Macrophage marker which is also captured by other markers. Mhm, let's actually check this and see what correlates most strongly with CD68.

<<results='markup',tiny=F>>=
cd68CoLinModel = lm(CD68~.,
                    data=meanStainWide_Tranformed[,names(meanStainWide_Tranformed)!="PtSnty"])
summary(cd68CoLinModel)
@

So, the following correlate with CD68 (descriptions taken from the excel sheet):
\begin{itemize}
  \item CD8a (p$<$1e-10): Marker of cytotoxic T cells
  \item CD11b (p$<$1e-5): Integrin alpha M(ITGAM). $\alpha$M$\beta$2 is expressed on the surface of many leukocytes involved in the innate immune system, including monocytes, granulocytes, macrophages, and natural killer cells.
  \item CD152 (p$<$1e-2): Check point inhibitor protein.
  \item CD3 (p$<$1e-2): General T Cell Marker
  \item HistoneH3 (p$<$5e-2): Generic Cell Marker
\end{itemize}

The correlation with t-cell markers is interesting. Perhaps this reflects a general immune response? If there are a lot of macrophages there are also a lot of t-cells? The check point inhibitor is kind of weird. Is this checkpoint inhibitor maybe only expressed on macrohpages?

No, according to Wikipedia it's expressed on t-cells. So, I guess that goes with the t-cell theme.

At this point it's a bit difficult to tell which marker to drop. I'm hesitant to drop cd68 all together, since I like it as a macrophage marker. I also don't want to drop the t-cell markers, if I don't have to. The one that seems to contain the least extra information is CD11b, as it's simply a generic immune marker. Let's drop this for now and revise later if this seems not appropriate.
<<results='markup'>>=
# Remove CD11b
meanStainWide_Tranformed = meanStainWide_Tranformed[,names(meanStainWide_Tranformed)!="CD11b"]
# Rerun the model
meanStain_LogitModel = glm(PtSnty ~.,family=binomial(link='logit'),
                           data=meanStainWide_Tranformed)
# Check the VIFs
vifVec = vif(meanStain_LogitModel)
vifVec[order(vifVec,decreasing=T)]
@

Mhm, at this point there's still a fair bit of co-linearity. I could continue removing stains using biological reasoning, but it seems more thorough to do a sweep through all possible combinations of these variables and use that to decide which are the ones that contain the most information.

% =======================================================
% ---- Naive Logistic Model -----
\section{Sweep through Models with No Interactions}
The \texttt{sweep()} function allows to do ``model optimisation''. By default it takes the input model, tries to add or remove one covariates at a time and chooses the one option that gives the best improvement in AIC (it does not consider interaction terms). Let's try that here:
<<results='markup'>>=
# Start with the raw data again
meanStainWide_Tranformed = meanStain_Wide
preprocessParams = preProcess(meanStain_Wide[,3:dim(meanStain_Wide)[2]],
                              method=c("center", "scale"),verbose=T)
meanStainWide_Tranformed[,3:dim(meanStain_Wide)[2]] =
  predict(preprocessParams, meanStain_Wide[,3:dim(meanStain_Wide)[2]])

# Remove the coreId column so that it doesn't influence the analysis
meanStainWide_Tranformed = cbind(meanStainWide_Tranformed$PtSnty,
                                 meanStainWide_Tranformed[,3:ncol(meanStainWide_Tranformed)])
names(meanStainWide_Tranformed) = c("PtSnty",markerLabelsVec)

# Remove RR102, DNA193 and CD11b because of their high correlation
meanStainWide_LessCorr = meanStainWide_Tranformed[,
                      !(names(meanStainWide_Tranformed) %in% c("DNA193","RR102","CD11b"))]

# Do step-wise model optimisation
initModel = glm(PtSnty ~.,family=binomial(link='logit'),
                           data=meanStainWide_LessCorr)
naiveStepSearch = step(initModel,trace=0)
naiveStepSearch$anova
@

The results are interesting. It removes almost all the ``non-indicative stains'' (It removes RR101, AvantiLipid, XeBCK, SrBCK). The other stains it removes seem kind of generic:
\begin{itemize}
  \item CD4: found on the surface of immune cells such as T helper cells, monocytes, macrophages, and dendritic cells.
  \item Ki67: marker of cell proliferation
  \item CD20: B Cell Marker
  \item CollagenI: part of the extracellular matrix.
  \item B7-H4: immune checkpoint protein expressed on the surface of antigen presenting cells
  \item CD3 (p$<$1e-2): General T Cell Marker
  \item HistoneH3 (p$<$5e-2): Generic Cell Marker
  \item HLA-DR: HLA-DR is an MHC class II cell surface receptor on antigen presenting cells. Upregulation can indicate immune stimulation (wikipedia)
  \item p53: involved in DNA repair. 70-90\% of ovarian tumors have mutated p53
  \item CD45: Protein tyrosine phosphatase, receptor type, C. Common antigen on leukocytes
  \item B7-H3: immune checkpoint protein
\end{itemize}

But it does leave DNA191 in! Also, these results have to be taken with a bit of a grain of salt: Which stains I remove is to some extend arbitrary, when looking at the detailed output of the stepping search often many stains would give the same final output. It would be good to do this stepping with a biologist who knows which stains would be interesting/useful to keep! Similarly, the results of what's in the final model depends on what I start with. If I don't remove DNA191 the results are different:
<<results='markup'>>=
initModel = glm(PtSnty ~.,family=binomial(link='logit'),
                           data=meanStainWide_Tranformed)
naiveStepSearch_Full = step(initModel,trace=0)
naiveStepSearch_Full$anova
@

Weirdly this keeps both DNA stains and has a lower AIC. But it throws out more of the normal stains, and still has the VIF problem:
<<results='markup'>>=
vifVec = vif(naiveStepSearch_Full)
vifVec[order(vifVec,decreasing=T)]
@

In contrast, the reduced model with DNA193 removed looks better:
<<results='markup'>>=
vifVec = vif(naiveStepSearch)
vifVec[order(vifVec,decreasing=T)]
@

Though still not great... Nevertheless I will focus on this model (the one with only DNA191) for now. Let's plot the coefficients again.
<<Fig_redModCoeff,tidy=F,results='markup',fig.pos="t", fig.cap="Importance of the different stains according to the reduced logistic model. Asterisk indicates level of statistical support for non-zero contribution from this stain (T-test: *p$<$0.05,**p$<$0.01).">>=
confLevel = 0.95 # Statistical confidence indicated by error bars

PlotCoefficients = function(model,confLevel=0.95,yLim=c(-25,25),yPos=20,starSize=7,errBarWidth=.8) {
  logitMCoeffs = model$coefficients
  logitMStdErrs = summary(model)$coefficients[,2]

  # Normalise
  normFact = sum(abs(logitMCoeffs))
  logitMCoeffs = logitMCoeffs*100/normFact
  logitMStdErrs = logitMStdErrs*100/normFact
  confIntLogitCoeffs = data.frame(MarkerLabels=names(logitMCoeffs)[2:length(logitMCoeffs)],
                                  MeanCoeff=as.numeric(logitMCoeffs[2:length(logitMCoeffs)]),
                                  SE=logitMStdErrs[2:length(logitMStdErrs)],
                                  CI=rep(0,length(logitMStdErrs[2:length(logitMStdErrs)])))

  # Compute the confidence interval
  nSamples = nrow(model$data)
  confIntLogitCoeffs$CI = qt(confLevel/2+.5,nSamples)*confIntLogitCoeffs$SE

  # Order by size of contribution
  confIntLogitCoeffs$MarkerLabels = factor(confIntLogitCoeffs$MarkerLabels,
                                           levels = confIntLogitCoeffs$MarkerLabels[
                                             order(confIntLogitCoeffs$MeanCoeff,decreasing=F)
                                           ])

  # Plot
  p=ggplot(confIntLogitCoeffs,aes(x=MarkerLabels,y=MeanCoeff,fill=MeanCoeff)) +
    geom_bar(position=position_dodge(0.9), stat="identity") +
    geom_errorbar(aes(ymin=MeanCoeff-CI, ymax=MeanCoeff+CI),
                  width=errBarWidth,                    # Width of the error bars
                  position=position_dodge(0.9)) +
    theme_bw() +
    ylim(yLim) +
    ylab("Relative size of the coefficient (in %)") +
    xlab("") +
    scale_fill_gradient(low="red",high="green4") +
    ggtitle(paste("Coefficients of Reduced Logistic Model",sep=""))

  # Add stars to indicate significance
  pValVec = summary(model)$coefficients[,4]
  for(marker in confIntLogitCoeffs$MarkerLabels) {
    if (pValVec[marker] < 0.01) {
      p = p + annotate("text", x = marker, y = yPos,
                       label = "**", size = starSize)
    } else if (pValVec[marker] < 0.05) {
      p = p + annotate("text", x = marker, y = yPos,
                       label = "*", size = starSize)
    }
  }

  # Flip the axes
  p = p + coord_flip()
  return(p)
}
PlotCoefficients(naiveStepSearch)
@

\section{Cross Validation}
Deviance is one way of evaluating our models, however, it's  somewhat difficult to interpret. Since we are trying to build a classifier, an idea of the models accuracy in predicting unseen patients would be a more intuitive and useful number. Thus, let's do a cross-validation test, to see how well our models classify. First make a function to do v-fold cross classification on the data:
<<results='markup'>>=
# Function to do a v-fold cross validations (v different ways of splitting
# the data into training and testing). This code is adopted from:
# https://www.stat.berkeley.edu/~s133/Class2a.html

LogisticCrossVal = function(nIter,v,formula,data){
  accuracyVec = rep(0,nIter)
  for (i in seq(nIter)) {
    # Split the data into training and testing.
    # It will assign each core into one of nFold groups. When it's this folds turn
    # the cores in this fold will be the testing set.
    nSamples = nrow(meanStainWide_Tranformed)
    grps = cut(1:nSamples,nFolds,labels=FALSE)[sample(1:nSamples)]

    # Do the validation
    pred = lapply(1:nFolds,function(i,formula,data){
    	    omit = which(grps == i)
          z = glm(formula,family=binomial(link='logit'),data=data[-omit,])
          predictions = predict(z,data[omit,],type='response')
          predictions = ifelse(predictions > 0.5,1,0)
          ClasificError = 1-mean(predictions != data[omit,]$PtSnty)
    	    },formula,data)

    accuracyVec[i] = mean(unlist(pred))
  }

  return(accuracyVec)
}
@
And now apply it:
<<FigModelCrossVal1, results='markup',warning=FALSE,,fig.pos="t",fig.cap="Mean accuracy achieved during cross-validation. The model based on the step search with DNA193 removed does best.">>=
nIter = 100
nFolds = 5

# Do the cross validation
fullModAccVec = LogisticCrossVal(nIter,nFolds,meanStain_LogitModel$formula,
                                 meanStainWide_Tranformed)
redModAccVec = LogisticCrossVal(nIter,nFolds,naiveStepSearch$formula,
                                meanStainWide_Tranformed)
redModAccVec_BothDNAs = LogisticCrossVal(nIter,nFolds,naiveStepSearch_Full$formula,
                                         meanStainWide_Tranformed)

# Plot the results
xValidResult = data.frame(Accuracy=c(fullModAccVec,redModAccVec,redModAccVec_BothDNAs),
                          Model=as.factor(c(rep(0,nIter),rep(1,nIter),rep(2,nIter))))
ggplot(xValidResult,aes(x=Model,y=Accuracy,fill=Model)) +
  geom_boxplot() +
  xlab("") +
  scale_fill_discrete(breaks=seq(0,2),labels=c("Model based\n on all stains",
                                               "Reduced Model",
                                               "Reduced Model\n with DNA191\n and DNA193"))
@

\section{Further Refinement}
The model I get out of the \texttt{step()} optimisation still contains some covariates whose coefficients are not significant. Let's remove them and see what effect that has on the model.

Firstly, what are the coefficients and their p-values?
<<results='markup'>>=
pValVec = summary(naiveStepSearch)$coefficients[,4]
pValVec[order(pValVec,decreasing=T)]
@

This suggests removing CD163. CD163 is a monocyte/macrophage lineage marker, and as such seems to be the same as CD68. Is it co-linear with it?
<<results='markup'>>=
cd163Model = lm(CD163~.,meanStainWide_Tranformed[,2:length(meanStainWide_Tranformed)])
summary(cd163Model)
@
Interestingly not. But it is strongly correlated with CD16, a generic immune marker.

Let's drop it.
<<results='markup'>>=
minimalModel = update(naiveStepSearch,.~.-CD163)
summary(minimalModel)
@

The next one to drop seems to be CD14 (again a macrophage marker). Let's drop this:
<<results='markup'>>=
minimalModel = update(minimalModel,.~.-CD14)
summary(minimalModel)
@

The next one to drop is PD-L2:
<<results='markup'>>=
minimalModel = update(minimalModel,.~.-`PD-L2`)
summary(minimalModel)
@

And then CD8a (cytotoxic T-cells). Note: the AIC has remained almost unchanged up to now (Before: \Sexpr{naiveStepSearch$aic}, Now: \Sexpr{minimalModel$aic})
<<results='markup'>>=
minimalModel = update(minimalModel,.~.-`CD8a`)
summary(minimalModel)
@

Now the p-values are all below 0.1 and the AIC is also lower than any other model so far (AIC = \Sexpr{minimalModel$aic}). How are the VIFs?

<<results='markup'>>=
vifVec = vif(minimalModel)
vifVec[order(vifVec,decreasing=T)]
@

Mhm, still not great. How does the plot look like?
<<Fig_minModCoeff,tidy=F,results='markup',fig.pos="h", fig.cap="Importance of the different stains according to the reduced logistic model. Asterisk indicates level of statistical support for non-zero contribution from this stain (T-test: *p$<$0.05,**p$<$0.01).">>=
PlotCoefficients(minimalModel,yLim=c(-30,30),yPos=22,errBarWidth=.4)
@

How is it's performance?
<<FigModelCrossVal2, results='markup',warning=FALSE,,fig.pos="h",fig.cap="Mean accuracy achieved during cross-validation. The minimal model still does as well as before removing the extra stains.">>=
nIter = 100
nFolds = 5

# Do the cross validation
minModAccVec = LogisticCrossVal(nIter,nFolds,minimalModel$formula,
                                meanStainWide_Tranformed)

# Plot the results
xValidResult = data.frame(Accuracy=c(fullModAccVec,redModAccVec,
                                     redModAccVec_BothDNAs,minModAccVec),
                          Model=as.factor(c(rep(0,nIter),rep(1,nIter),
                                            rep(2,nIter),rep(3,nIter))))
ggplot(xValidResult,aes(x=Model,y=Accuracy,fill=Model)) +
  geom_boxplot() +
  xlab("") +
  scale_fill_discrete(breaks=seq(0,3),labels=c("Model based\n on all stains",
                                               "Reduced Model",
                                               "Reduced Model\n with DNA191\n and DNA193",
                                               "Minimal Model"))
@
So, it has been able to maintain its performance!

\section{Biological Interpretation}
Now that we have reduced the data to a small number of stains (\Sexpr{length(minimalModel$coefficients)}) let's see what the results suggest. What is the biological meaning of our results?
<<Fig_minModCoeff_Annot,tidy=F,results='markup',fig.pos="h", fig.cap="Importance of the different stains according to the reduced logistic model. Asterisk indicates level of statistical support for non-zero contribution from this stain (T-test: *p$<$0.05,**p$<$0.01).">>=
p = PlotCoefficients(minimalModel,yLim=c(-50,50),yPos=22,errBarWidth=.4)

# Annotate the markers
yPos = 37
tSize = 2.5
# Positive
p = p + annotate("text", x = "CD68", y = yPos,
                       label = "Monocytes/\n Macrophages", size = tSize)
p = p + annotate("text", x = "CD19", y = yPos,
                       label = "B-Cells", size = tSize)
p = p + annotate("text", x = "CD196", y = yPos,
                       label = "Immature Dendritic Cells/\n Memory T-Cells", size = tSize)
p = p + annotate("text", x = "`E-cadherin`", y = yPos,
                       label = "Epithelial Phenotype", size = tSize)
p = p + annotate("text", x = "p21", y = yPos,
                       label = "Cell Cycle Inhibitor", size = tSize)
p = p + annotate("text", x = "DNA191", y = yPos,
                       label = "NA", size = tSize)
p = p + annotate("text", x = "DNA191", y = yPos,
                       label = "NA", size = tSize)
p = p + annotate("text", x = "CD44s", y = yPos,
                       label = "Cell-Cell Interaction", size = tSize)
p = p + geom_rect(aes(xmin = "Vimentin", xmax = 16.5, ymin = 25, ymax = 50),
               fill = "transparent", color = "green4", size = 1.5)

# Negative
yPos = -37
p = p + annotate("text", x = "Vimentin", y = yPos,
                       label = "Mesenchymal Phenotype", size = tSize)
p = p + annotate("text", x = "pS6", y = yPos,
                       label = "Increased Translation", size = tSize)
p = p + annotate("text", x = "CD16", y = yPos,
                       label = "Monocytes/\n Macrophages/\n NK Cells", size = tSize)
p = p + annotate("text", x = "CD152", y = yPos,
                       label = "Checkpoint Inhibitor", size = tSize)
p = p + annotate("text", x = "`Beta-catenin`", y = yPos,
                       label = "Proto-Oncogene\n Wnt Pathway", size = tSize)
p = p + annotate("text", x = "CD134", y = yPos,
                       label = "T-Cell Activation\n Survival", size = tSize)
p = p + annotate("text", x = "FoxP3", y = yPos,
                       label = "Regulatory T-Cells", size = tSize)
p = p + annotate("text", x = "CD25", y = yPos,
                       label = "Activated T- and B-Cells", size = tSize)
p = p + geom_rect(aes(xmin = 0, xmax = "CD44s", ymin = -25, ymax = -50),
               fill = "transparent", color = "red", size = 1.5)

p
@

A lot of the correlation make biological sense (e.g. more mesenchymal phenotypes correlated with worse prognosis). When looking some of these markers up on wikipedia they all have the corresponding correlation with cancer.

Two are interesting:
CD44 can be both pro and anti cancer, depending on post-translational modifications/splicing (i.e. context). For ovarian, however, CD44 has been correlated in the past with good outcome ( Sillanpaa S, Anttila MA, Voutilainen K, Tammi RH, Tammi MI, Saarikoski SV, Kosma VM (Nov 2003). "CD44 expression indicates favorable prognosis in epithelial ovarian cancer". Clinical Cancer Research. 9 (14): 5318â€“24. PMID 14614016.). It's a hialuronic acid receptor.

CD134 is associated with longer t-cell survival. Similarly, FoxP3 indicates activated T-reg cells. Maybe we have protection from T-cells here?

\section{A Model on De-Correlated Data}
The model at this point still has very high VIFs which means there is still a lot of co-linearity. Also the errors on for example CD25 are very high, so there seems to be some kind of conflicting signal. Let's try to reduce the VIF to say 10 or 20 before doing model selection, so that the coefficient estimates (which model selection relies on!) are more reliable.

Below I define a set of functions that will de-correlate the data (\texttt{DecorrelateVariables()}) and do a stepping search on it that does both stepping (to minimise AIC) and dropping the variable with the highest VIF (to further reduce the VIFs).
<<results='markup'>>=
# Function to decorrelate the variables in an R regression model (of class lm or glm).
# It drops the variable with the highest VIF until all VIFs are below targetVIF. VIF is a
# measure of how well one variable can be expressed as a linear combination of the others.
DecorrelateVariables = function(model,targetVIF,verbose=T) {
  library(car)
  repeat{
    # Identify the variable with the maximum VIF 
    vifVec = vif(model)
    maxVIF = max(vifVec)
    # vif() output changes if there are factor variables in the model.
    # Adjust for this.
    if(is.null(dim(vifVec))) { # No factor
      varToDrop = names(vifVec)[which.max(vifVec)]
    } else{ # Factor
      varToDrop = names(vifVec[,1])[which.max(vifVec[,1])]
    } 
    
    # If the maximum VIF is below the target stop
    if (maxVIF<=targetVIF){
      break
    } else { # Else, drop that variable
      model = update(model,paste0(".~.-",varToDrop))
      if(verbose) {print(paste0("Dropping ",varToDrop," with VIF ",maxVIF))}
    }
  }
  return(model)
}
# Function to compute the accuracy of the model in predicting the provided input variables
LmAccuracy = function(model,classifier=F) {
  if(classifier) {
     accuracy = mean(ifelse(model$fitted.values>0.5,1,0)==model$y)
   } else {
     accuracy = mean(abs(model$residuals))
   }
}

# Function to do alternating AIC reduction via step() and VIF reduction
#(de-correlation) by dropping the variable with the highest VIF.
AICVIFCoElimination=function(model,targetVIF=10,classifier=T,verbose=T){
  output=data.frame(aic=c(),accuracy=c(),maxVIF=c(),remainingVar=c(),model=c())
  vifVec = vif(model)
  maxVIF = max(vifVec)
  repeat{
    # Drop variables to minimise AIC
    if(verbose) {print("Minimising AIC...")}
    model=step(model,trace=0)
    nVariables = length(attr(terms(model),"variables"))-2
    accuracy = LmAccuracy(model,classifier)
    if(verbose) {print(paste("Remaining Variables:",nVariables,"AIC:",
                             model$aic,"Accuracy:",accuracy))}
    output=rbind(output,cbind(model$aic,accuracy,maxVIF,nVariables,c(model$formula)))
    
    # Drop the variable with the maximum VIF
    if(nVariables<2) break
    vifVec = vif(model)
    maxVIF = max(vifVec)
    # vif() output changes if there are factor variables in the model.
    # Adjust for this.
    if(is.null(dim(vifVec))) { # No factor
      varToDrop = names(vifVec)[which.max(vifVec)]
    } else { # Factor
      varToDrop = names(vifVec[,1])[which.max(vifVec[,1])]
    } 
    if(verbose) {print(paste0("Minimising Co-linearity - Dropping ",varToDrop))}
    model = update(model,paste0(".~.-",varToDrop)) # Drop it
    accuracy = LmAccuracy(model,classifier)
    nVariables = length(model$coefficients)-1
    if(verbose) {print(paste("Remaining Variables:",nVariables,"AIC:",
                             model$aic,"Accuracy:",accuracy))}
    output=rbind(output,cbind(model$aic,accuracy,maxVIF,nVariables,c(model$formula)))
    if(length(vifVec)<2) break
  }
  return(output)
}
@

Let's apply them to the data. Decorrelate the data to a maximum VIF of 100,20,10 and then do stepping followed by further reduction of the VIF.

<<results='markup'>>=
initModel = glm(PtSnty ~.,family=binomial(link='logit'),
                           data=meanStainWide_Tranformed)
reducedCoLinModelArr100 = AICVIFCoElimination(DecorrelateVariables(initModel,100,verbose=F)
                                              ,verbose=F)
reducedCoLinModelArr20 = AICVIFCoElimination(DecorrelateVariables(initModel,20,verbose=F)
                                             ,verbose=F)
reducedCoLinModelArr10 = AICVIFCoElimination(DecorrelateVariables(initModel,10,verbose=F)
                                             ,verbose=F)
@

Say we tolerate a maximum VIF of 25. What are the best AICs we get?

<<results='markup'>>=
targetVIF = 25
best100 = reducedCoLinModelArr100[which.min(
  reducedCoLinModelArr100[unlist(reducedCoLinModelArr100$maxVIF)<targetVIF,1]),]
best20 = reducedCoLinModelArr20[which.min(
  reducedCoLinModelArr20[unlist(reducedCoLinModelArr20$maxVIF)<targetVIF,1]),]
best10 = reducedCoLinModelArr10[which.min(
  reducedCoLinModelArr10[unlist(reducedCoLinModelArr10$maxVIF)<targetVIF,1]),]
print(best100[1:4])
print(best20[1:4])
print(best10[1:4])
@

It seems like when we start from maxVIFs$=100$ we get the worst model in terms of AIC and maxVIF. Beyond that it depends on if we want a small VIF or a small AIC. How do these models do in cross-validation?

<<FigModelCrossVal3, results='markup',warning=FALSE,,fig.pos="h",fig.cap="Mean accuracy achieved during cross-validation. The minimal model still does as well as before removing the extra stains.">>=
best100Model = glm(paste0(best100[,5]),family=binomial(link='logit'),
                           data=meanStainWide_Tranformed)
best20Model = glm(paste0(best20[,5]),family=binomial(link='logit'),
                           data=meanStainWide_Tranformed)
best10Model = glm(paste0(best10[,5]),family=binomial(link='logit'),
                           data=meanStainWide_Tranformed)

# Cross-validation
nIter = 100
nFolds = 5

# Do the cross validation
best100AccVec = LogisticCrossVal(nIter,nFolds,best100Model$formula,
                                meanStainWide_Tranformed)
best20AccVec = LogisticCrossVal(nIter,nFolds,best20Model$formula,
                                meanStainWide_Tranformed)
best10AccVec = LogisticCrossVal(nIter,nFolds,best10Model$formula,
                                meanStainWide_Tranformed)

# Plot the results
xValidResult = data.frame(Accuracy=c(minModAccVec,best100AccVec,
                                     best20AccVec,best10AccVec),
                          Model=as.factor(c(rep(0,nIter),rep(1,nIter),
                                            rep(2,nIter),rep(3,nIter))))
ggplot(xValidResult,aes(x=Model,y=Accuracy,fill=Model)) +
  geom_boxplot() +
  xlab("") +
  scale_fill_discrete(breaks=seq(0,3),labels=c("Best Model from Before",
                                               "Best Model from Initial VIF 100",
                                               "Best Model from Initial VIF 20",
                                               "Best Model from Initial VIF 10"
                                               ))
@

The one starting from maxVIF=20 seems to be much better than the others. It has 13 variables, the one from VIF10 has 12. What is the difference?
<<results='markup'>>=
both=names(best10Model$coefficients) %in% names(best20Model$coefficients)
names(best10Model$coefficients)[both]
@

So, they share \Sexpr{sum(both)} variables. Model20 in addition contains:

<<results='markup'>>=
only20 = !(names(best20Model$coefficients) %in% names(best10Model$coefficients))
names(best20Model$coefficients)[only20]
@

Whereas Model 10 contains:
<<results='markup'>>=
names(best10Model$coefficients)[!both]
@

What do they look like?
<<Fig_Model20,tidy=F,results='markup',fig.pos="h", fig.cap="Importance of the different stains according to the logistic model with maxVIF 20. Asterisk indicates level of statistical support for non-zero contribution from this stain (T-test: *p$<$0.05,**p$<$0.01).">>=
p = PlotCoefficients(best20Model,yLim=c(-50,50),yPos=22,errBarWidth=.4)
# Annotate the markers
yPos = 37
tSize = 2.5
# Positive
p = p + annotate("text", x = "CD196", y = yPos,
                       label = "Immature Dendritic Cells/\n Memory T-Cells", size = tSize)
p = p + annotate("text", x = "CD19", y = yPos,
                       label = "B-Cells", size = tSize)
p = p + annotate("text", x = "`E-cadherin`", y = yPos,
                       label = "Epithelial Phenotype", size = tSize)
p = p + annotate("text", x = "HistoneH3", y = yPos,
                       label = "Generic Cell Marker", size = tSize)
p = p + annotate("text", x = "p21", y = yPos,
                       label = "Cell Cycle Inhibitor", size = tSize)
p = p + annotate("text", x = "DNA191", y = yPos,
                       label = "NA", size = tSize)
p = p + annotate("text", x = "DNA191", y = yPos,
                       label = "NA", size = tSize)
p = p + annotate("text", x = "CD44s", y = yPos,
                       label = "Cell-Cell Interaction", size = tSize)
p = p + geom_rect(aes(xmin = "Vimentin", xmax = 13.5, ymin = 25, ymax = 50),
               fill = "transparent", color = "green4", size = 1.5)

# Negative
yPos = -37
p = p + annotate("text", x = "Vimentin", y = yPos,
                       label = "Mesenchymal Phenotype", size = tSize)
p = p + annotate("text", x = "pS6", y = yPos,
                       label = "Increased Translation", size = tSize)
p = p + annotate("text", x = "CD16", y = yPos,
                       label = "Monocytes/\n Macrophages/\n NK Cells", size = tSize)
p = p + annotate("text", x = "CD134", y = yPos,
                       label = "T-Cell Activation\n Survival", size = tSize)
p = p + annotate("text", x = "CD152", y = yPos,
                       label = "Checkpoint Inhibitor", size = tSize)
p = p + annotate("text", x = "CD25", y = yPos,
                       label = "Activated T- and B-Cells", size = tSize)
p = p + geom_rect(aes(xmin = 0, xmax = "CD44s", ymin = -25, ymax = -50),
               fill = "transparent", color = "red", size = 1.5)

p
@

So this model is almost the one I got previously, just with fewer variables. Interestingly it seems to be even more robust in the cross-validation.

Let's look at model10:
<<Fig_Model10,tidy=F,results='markup',fig.pos="h", fig.cap="Importance of the different stains according to the logistic model with maxVIF 10. Asterisk indicates level of statistical support for non-zero contribution from this stain (T-test: *p$<$0.05,**p$<$0.01).">>=
PlotCoefficients(best10Model,yLim=c(-30,30),yPos=22,errBarWidth=.4)
@

Yeah, that doesn't look as nice. Strange it wants CD14 and CollagenI when they're not significant...

As of now the one I prefer most is probably model20, which has the best AIC and still okish VIFs. The AIC of the model from the previous section was \Sexpr{minimalModel$aic}, model20 has an AIC of \Sexpr{best20Model$aic}. So the AIC is slightly worse, but interestingly it's performance in cross-validation is slightly better. It's VIFs are also much better (max now is around 20, before it was 40. It's strange though that we're now picking up Histones...

Just for completeness, here are its summary and vifs:
<<results='markup'>>=
summary(best20Model)
vifVec = vif(best20Model)
vifVec[order(vifVec,decreasing=T)]
@

Actually, CD25 and CD19 seem to be the two variables with problematic VIFs. Maybe that's why their standard errors are inflated? What happens if I remove them? The current aic is \Sexpr{best20Model$aic}

<<results='markup'>>=
best20Model_NoCd25 = update(best20Model,.~.-CD25)
summary(best20Model_NoCd25)
vifVec = vif(best20Model_NoCd25)
vifVec[order(vifVec,decreasing=T)]
@

The model is much worse now, but the VIFs are fine... What if I remove CD19 instead?

<<results='markup'>>=
best20Model_NoCd19 = update(best20Model,.~.-CD19)
summary(best20Model_NoCd19)
@

Not really a huge improvement either...
Yeah, let's leave it here for now. This seems like a decent model

\section{Dependence of Platinum Response on Cancer Grade}
The results from the logisitic model are very interesting, because they suggest that it is less something about the cancer that makes the difference, but more the environment. However, it is clear that the environment does change over time and what might be good early in cancer development might be bad later on. It is very plausible that the precise influence of, for example, the immune system is very dependent on the stage of the tumour. This could also explain the large error bars for some of the coefficients. Perhaps, stains like CD25 are very important for a sub-part of the patients but not others.

In order to see how our results depend on the tumour class, let's incorporate them into the model.
To do so I first have to associate each core with its grade.
<<results='markup'>>=
patientDB = read.csv("fluidigm_patient_response.csv")

meanStain_Staged = data.frame(CoreId=meanStain_Wide$CoreId,meanStainWide_Tranformed,Stage=rep(0,nrow(meanStain_Wide)))

for (coreId in meanStain_Staged$CoreId){
  patientId = which(patientDB$core.1==coreId)
  if(length(patientId)==0) patientId = which(patientDB$core.2==coreId)
  
  # Stage the patient
  stage = patientDB$stage[patientId]
  meanStain_Staged$Stage[meanStain_Staged$CoreId==coreId] = stage
  print(paste(patientId,stage))
}
meanStain_Staged$Stage = as.factor(meanStain_Staged$Stage)
levels(meanStain_Staged$Stage) = levels(patientDB$stage)
summary(meanStain_Staged$Stage)
@

This does suggest a heavy skew towards patients with stage 3C and 4 cancer. This might make the analysis difficult, but maybe if we group accordingly we can pull something out. The cancer grading works as follows:
\begin{itemize}
\item Stage I: Local disease confined to the ovaries
\item Stage II: Cancer has spread to other pelvic structures (e.g. uterus, fallopian tubes, bladder, the sigmoid colon, or the rectum). But not lymph nodes or distant sides.
\item Stage III: Cancer has spread to the abdomen and/or the draining nodal beds.
\item Stage IV: Metastatic Lesions outside the abdomen (e.g. liver or lung).
\end{itemize}

For a detailed breakdown see https://www.cancer.org/cancer/ovarian-cancer/detection-diagnosis-staging/staging.html.

Let's make 4 groups for now and then take it from there.

<<results='markup'>>=
meanStain_Staged$StageCoarse[meanStain_Staged$Stage=="1C"] = 1
meanStain_Staged$StageCoarse[meanStain_Staged$Stage=="2B"] = 2
meanStain_Staged$StageCoarse[meanStain_Staged$Stage=="2C"] = 2
meanStain_Staged$StageCoarse[meanStain_Staged$Stage=="3A"] = 3
meanStain_Staged$StageCoarse[meanStain_Staged$Stage=="3B"] = 3
meanStain_Staged$StageCoarse[meanStain_Staged$Stage=="3C"] = 3
meanStain_Staged$StageCoarse[meanStain_Staged$Stage=="4"] = 4
@

Start the modelling process. For now let's model grade as a continous variable.
<<results='markup'>>=
meanStain_Staged$StageCoarse = as.numeric(meanStain_Staged$StageCoarse)
omit = c(which(names(meanStain_Staged)=="CoreId"),which(names(meanStain_Staged)=="Stage"))
initModel = glm(PtSnty ~.,family=binomial(link='logit'),
                    data=meanStain_Staged[,-omit])
stagedModelArr = AICVIFCoElimination(DecorrelateVariables(initModel,100,verbose=F)
                                              ,verbose=F)
stagedModel = glm(paste0(stagedModelArr[4,5]),family=binomial(link='logit'),
                    data=meanStain_Staged[,-omit])
summary(stagedModel)
vif(stagedModel)
@

Try interactions
<<results='markup'>>=
stagedModel = update(stagedModel,.~.+StageCoarse:CD196+StageCoarse:Vimentin+
                       StageCoarse:CD16+StageCoarse:CD134+StageCoarse:CD44s+
                       StageCoarse:CD152+StageCoarse:HistoneH3+StageCoarse:DNA191)
stagedModel=step(stagedModel)
summary(stagedModel)
@

<<results='markup'>>=
#   source("../Utils.R")
# dum = data.frame(meanStain_Staged,FittedVals=bestModel$fitted.values)
# dum$StageCoarse = as.numeric(dum$StageCoarse)
# markerNames = names(bestModel$coefficients)[2:(length(names(bestModel$coefficients))-3)]
# PcaPlot(dum,markerNames,c("FittedVals"))
@

<<results='markup'>>=

# initModel = glm(PtSnty ~.,family=binomial(link='logit'),
#                            data=meanStainWide_LessCorr)
# naiveStepSearch = step(initModel,trace=1,direction="both")
# naiveStepSearch$anova

# bothDNA = glm(PtSnty ~ DNA191+DNA193,family=binomial(link='logit'),
#                            data=meanStainWide_Tranformed)
#
# onlyDNA193 = glm(PtSnty ~ DNA193,family=binomial(link='logit'),
#                            data=meanStainWide_Tranformed)
# dna193AccVec = LogisticCrossVal(nIter,nFolds,onlyDNA193$formula,
#                                          meanStainWide_Tranformed)
# bothDNAAccVec = LogisticCrossVal(nIter,nFolds,bothDNA$formula,
#                                          meanStainWide_Tranformed)
#
# mean(bothDNAAccVec)
# mean(dna193AccVec)
#
# m = lm(DNA191~.,meanStainWide_Tranformed)
# summary(m)
# summary(onlyDNA)
@
\end{document}